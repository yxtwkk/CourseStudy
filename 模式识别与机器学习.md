# 人工智能简介

## 人工智能

构造智能机器（智能计算机，智能系统）的科学和工程，使机器模拟、延伸、扩展人类智能

人类智能包括：感知、学习、思维、行为

## 人工智能研究内容

（1）机器感知（模式识别）

a.模式识别、模式匹配

b.计算机视觉、图像视频分析

c.语音识别、自然语言理解

（2）机器学习

a.从数据或经验学习模型或程序

b.监督学习、无监督学习、半监督学习等

（3）机器思维（问题求解）

专家系统、自动问答、机器定理证明、下棋等

（4）智能行为

机器人动作、自动驾驶、无人机等

> 需要区别工业机器人和智能机器人的区别===是否有脑活动参与是判断机器行为是否属于人工智能的（除去纯计算，因为计算机设计的目的之一就是帮助人来进行计算）
>

# 计算机模式识别

使计算机模仿人的感知能力，从感知数据中提取信息（判别物体和行为、现象）的过程

包括三个步骤：数据获取->模式分割->模式识别

模式识别是将非结构化的数据转换成结构化知识的过程

## 模式识别、机器学习和数据挖掘的区别与联系

机器学习：从数据、经验中获取知识、规则、模型、参数的过程=>主要研究理论算法，大部分针对分类

模式识别：主要这对感知数据，面向应用

数据挖掘：主要针对非感知和混合数据

机器学习、模式识别和数据挖掘需要用到的方法包括：分类、聚类特征提取

## 模式识别形式化

我们需要将物理直观概念或关系或过程通过转化成数学符号，进而进行计算机程序化。

模式的两个层次包括：样本和类别

模式识别的核心技术：模式分类

（1）检测：2-class

（2）判别：2-class，multi-class

（3）分类器设计：机器学习

相关问题：特征提取和特征选择

## 识别对象表示

（1）特征矢量：
$$
X=[x1,x2,x3….,xn]^T
$$
（2）特征空间（又名线性空间或欧式空间，区别于马氏空间）

> 通过特征矢量之间的距离，可以表征两个样本之间的差异
>

## 分类器表示

（1）类别模型：
$$
Mi = M(X,θi)
$$
其中，x表征特征向量，θi表征参数

（2）判别函数：
$$
yi=f(x,ωi)
$$
每一个类别都有一个判别函数或者类别函数；其中，yi的值越大，表征x属于哪一类（即 相似度）
$$
d(x,wi)=-f(x,wi)
$$
d表征x与wi的距离，即，差异度越小，距离越大

（3）决策面：
$$
f(x,wi)=f(x,wj)
$$
决策面是两个类别的判别函数相等的点构成的集合，而判别函数是每一个类别都有一个类别函数

特征矢量表示的好处：

（1）一个模式（样本）对应空间中的一个点

（2）容易计算样本之间的距离

欧式空间的特性：

（1）欧式距离具有坐标不变性（即，样本在欧式空间的直线距离不随坐标的变化而改变）

（2）Metric：

d(x1,x2)+d(x1,x3)>d(x2,x3)

d(x1,x2)-d(x1,x3)<d(x2,x3)

其中x1,x2,x3表示特征空间中的一个点

## 特征空间的分类

空间划分：

（1）距离度量/相似度：最小距离或者最大相似度

![公式一](模式识别\公式一.PNG)

（2）决策区域：下图所示表征的是任意两点的中线连成的区域

![公示二](模式识别\公示二.PNG)

线性可分/线性不可分是指，两个模式在二维空间可以用直线或在多维空间可以用平面分割即为线性可分

特征空间可以线性可分，即为线性判别，若不是线性可分，即为非线性判别![图一](模式识别\图一.PNG)

## 模式识别系统流程

完整的识别流程：

![流程图一](模式识别\流程图一.PNG)

识别-训练过程（深度学习：特征表示与分类器同时学习 End-End）

训练/测试过程中的模式预处理--特征提取必须完全一致

![流程图二](模式识别\流程图二.PNG)

## 分类器训练（学习）过程

模式进行识别的过程重要的一环是对分类器进行选择，以及每一个分类器需要设定的参数，以下流程表征选定模型的情况下，如何为分类器选择合适的参数

其中，分类器的训练和评价过程必须分开，大致流程为

将样本数据分为两类，一类是训练数据，一类是测试数据

训练数据->模型选择->给定分类器结构->参数估计

测试数据对训练得到的模型进行分类

因为在学习过程中需要进行模型选择，所以我们需要将训练数据再次划分为Estimat.set（用来选择模型的数据）和Validat.set（用来验证模型是否正确的数据）

## 数据划分方式

整体上划分为训练数据和测试数据，训练数据又需要划分为Estimat.set和Validat.set

数据划分方式有三种：

（1）cross-validation（rotation）：

将数据划分为n等份，每等份轮流做测试，其余部分用来做训练（这种方式又称为Leave-one-out LOO）

（2）HoldOut：将数据分为两等份

（3）Bootstrapping：每次随机拿出部分数据

## 泛化性能

泛化性能是指测试数据上的分类性能

在模型固定的情况下（模型固定，不是参数固定），训练样本越大，模型的泛化性能越好

过拟合/过学习：用复杂分类器能将训练数据分类错误率降到极低

在过拟合的情况下，泛化性能会下降

训练数据不变的情况下，分类器越复杂，对训练数据的拟合程度越高



